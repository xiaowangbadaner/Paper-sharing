#  SegNet

> A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation 

##  Abstract 

SegNet 的新颖之处在于解码器对其低分辨率输入特征映射进行上采样的方式，即解码器使用在相应编码器的 max-pooling 步骤中计算的池索引来执行非线性上采样。 

## Introduction

在解码过程中使用最大池化索引：1.改善了边界划分；2.减少了end to end 训练的参数数量；3. 这种形式的上采样可以整合到任何编码器-解码器架构中。

## Literature review

通过在FCN上附加一个循环神经网络(RNN)[10]并对其在大型数据集上进行微调，FCN的预测性能得到了进一步的改进。CRF-RNN网络可以附加到任何深度分割体系结构。

使用 CRF 所获得的感知性能提高是由于其核心前馈分割引擎缺乏良好的解码技术。

SegNet 使用解码器获得特征，以便进行精确的像素级分类。 

一个encoder由一个convolution with a filter bank一个element-wise tanh non-linearity，一个max-pooling和一个sub-sampling组成。

一个decoder通过使用sorted pooled indices来进行采样。

## Architecture

![1640013628024](\pic\1640013628024.png)

使用vgg16的前十三层作为basemodel，U型结构。

每一个encoder包含卷积+BN+ReLU。

利用最大池化实现了输入图像在小空间位移下的平移不变性。 

因为过多的采样会损失更多的图片信息（特别是边界细节），因此，在进行二次采样之前，有必要在编码器特征映射中捕获和存储边界信息。一般为了节省空间，值存储maxpool位置处的信息。

***DeconvNet使用了全连接层。***

与SegNet相比，U-Net不重用池索引，而是将整个特征映射(以消耗更多内存为代价)传输到相应的解码器，并将它们连接到上采样(通过反卷积)的解码器特征映射。与VGG网络结构不同，U-Net中没有conv5和max-pool 5块。另一方面，SegNet使用VGG网中所有预训练卷积层权值作为预训练权值 

#### Decoder Variants

许多分割网络共用相同的encoder，使用不同的decoder

![1640015439884](\pic\1640015439884.png)

####  Training

使用了的初始化策略： **Delving deep into rectifiers:Surpassing human-level performance on imagenet classification**

####  Analysis 

mIoU 度量是一个比类平均准确度更严格的度量，因为它惩罚假阳性预测。然而，mIoU 度量不是直接通过类平衡交叉熵损失优化。 这个指标并不总是符合人类对高质量分割的定性判断(等级)，mIoU有利于区域平滑，不评估边界精度。

 计算语义轮廓得分的关键思想是评估 f1度量。 它涉及到在给定像素容忍距离的情况下，计算预测类边界与地面真实类边界之间的精度和召回值。 

*  需要学习分割解码器 
* segnet的解码器比fcn更复杂，参数更多，效果也更好。
* 在时间和空间都允许的情况下，比较大的网络一般效果更好（衡量资源占用和精度）。

## Benchmarking

DeepLab-LargeFOV：减少全连接层的参数量，基本不会有太大的影响。

####  Road Scene Segmentation

实验中Segnet可以识别出较小的类。虽然deeplab-largefov在使用CRF后会产生最好的结果，但是较小的类会丢失。

**FCN with learnt deconvolution is clearly better than with fixed bilinear upsampling** 

很多模型的边界精度较差，添加CRF后可以提高一定的pixel acc和miou

####  SUN RGB-D Indoor Scenes 

大型室内数据集，有不同的传感器捕捉，分辨率不同，共37个类别，形状大小多变而且有遮挡部分。

室内场景比室外场景有更多的噪声。

所有深层体系结构都具有较低的mIoU和边界度量。

使用基于网格搜索的decse-crf 的最佳超参数，除了 DeepLab-LargeFOV-denseCRF 的 BF 评分指标之外，其他指标都变差了。也许可以找到更多的最佳设置，但是网格搜索过程过于昂贵，因为对于dense-crfs 需要大量的推理时间。

室内场景比较差的原因：1. 类的数量很大，许多类占据了图像的一小部分且出现频率低；2.模型无法适应场景的复杂变化。

##  discussion and future work

## conclusion

