# 20211118 vgg

> VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION

## Abstract

用来研究深层网络在大规模图像识别任务上的准确性。

使用3*3的卷积核来增加网络深度，进而将网络深度推到16-19层。

## Introduction

改进性能的尝试：

  1.利用较小的接收窗口和较小的第一层卷积步幅   2.在整个图像和多个尺度上对网络进行密集的训练和测试。

本文提出了深度对性能的影响。（使用了3*3的卷积核）

## Convert Configurations

### Architecture

1.减去各个通道的均值

2.使用3*3的卷积核（这是能提取上下左右和中间特征的最小尺寸）

3.使用1*1的卷积核来当作通道维的线性连接层

4.卷积步幅固定为1，输入使用padding来保证分辨率不变

5.使用最大池化层（2*2的池化窗口，步幅为2）。

### Configurations

卷积层的宽度比较小，从64通道开始，每个maxpooling后通道数乘2，直到达到512。

尽管VGG深度很大，但是权重数量并不比其余较浅的网络中的权重数量大，因为其他网络有比较大的卷积层宽度和感受野

### Discussion

全网络使用3*3的卷积核。

两个3 * 3的卷积核和5 * 5的卷积核有相同的感受野，三个就和7*7的卷积核有相同的感受野。

1.使decision function更有鉴别性；2.减少了参数（3 * 3^2 * C^2=27 * C^2;7^2 * C^2=49 * C^2;C为通道数）

1 * 1卷积是增加决策函数非线性能力而不影响感受野的办法。但在论文里是一个在相同维数的空间上的线性投影（输入和输出通道相同）。

## Classification Framework

### Training

用带动量的小批量梯度下降优化多项逻辑回归目标来训练。

网络参数更多，深度更大，但是使用小的卷积核带来的隐式正则化和某些层的预初始化带来了更快的收敛速度。

先训练浅层网络，然后把浅层网络迁移到深层网络的前四层和后三层全连接层，中间的层用随机初始化。

1.从原始图像随即裁剪224 * 224的图像；2.进行随机水平翻转和随机RGB颜色位移。

#### Training image size

设S为训练时的最小尺寸（224 * 224）。有两种方法设置S的尺寸。1.固定S；2.多尺度进行训练。

### Testing

用零填充（padding）来扩大感受野。

使用多个crop来评估网络。

### Implementation details

使用gpu在多个尺度上对未裁剪的图片进行训练和评估。也可以使用多gpu进行训练。

## classification experiment

### single scale evalution

使用局部响应归一化(A- lrn网络)并不能改进没有任何归一化层的模型。所以我们没有在更深的网络架构中使用normalisation。

1.深层网络效果更好；2.使用1 * 1卷积的网络C比使用3 * 3卷积的D效果差；3.使用额外的非线性单元确实有帮助（C>B），但是使用卷积核去接受上下文信息也很重要(D>C)

在文章提到数据集中，层数达到19时错误率就会饱和，更深的网络结构可能适应于更大的数据集。

比较两个3 * 3的深网和5 * 5的浅网的效果（他们拥有相同的感受野）。

**训练时尺度抖动(S∈[256，512])比固定最小边(S = 256或S = 384)的图像上进行训练的结果明显更好。**

### MULTI-SCALE EVALUATION

介绍了尺度抖动的作用（scale jittering）。会带来更好的结果。

### MULTI-CROP EVALUATION

using multiple crops performs slightly better than dense evaluation。

training scale S was
sampled from [256; 512], and three test scales Q were considered: {256, 384, 512}

### CONVNET FUSION

模型结果融合后会有更好的结果。

### COMPARISON WITH THE STATE OF THE ART

## CONCLUSION



